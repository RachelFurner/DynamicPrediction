{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to predict dynamic time stepping of an ocean model\n",
    "\n",
    "Written by Rachel Furner, April 2019.\n",
    "\n",
    "Collaborative work with colleagues at BAS, and the ATI\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read in the data\n",
    "2. Define input data and output data.\n",
    "3. Split into test and train data.\n",
    "4. Train the network\n",
    "5. Run predictions on test data and assess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Reshape\n",
    "from tensorflow.keras.layers import MaxPooling3D, Conv3D, UpSampling3D, Cropping3D\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StepSize = 1 #number of timesteps forward which we want to predict\n",
    "SkipOver = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data files as Xarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/Users/rachelfurner/JasminData/DynPred/'\n",
    "exp_list = ['4500yr_Windx0.50']\n",
    "file_names = ['state.0000000000.t001.nc']\n",
    "file_list =[]\n",
    "for exp in exp_list:\n",
    "    print(exp)\n",
    "    for file in file_names:\n",
    "        print(file)\n",
    "        file_list.append(os.path.join(DIR,exp,file))\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define Input output pairs\n",
    "Eventual aim is that inputs are full model field at t-stepsize and t, outputs are full model fields at t+StepSize.\n",
    "For now, input is just Temp at just at time step t, and output is Temp at t+stepsize.\n",
    "\n",
    "In future could involve lots of input variables.\n",
    "\n",
    "StepSize can be changed easily (defined further up) - plan to test different values and see how well things work.\n",
    "\n",
    "We take input,output pairs with 't' spaced by 'SkipOver' steps apart. Currently this is set as 1, but ideally would be larger, in bid to ensure some independance between samples. Balance between low values giving us lots of training samples, but also a desire for independant training samples\n",
    "\n",
    "Need to amend below to loop through multiple files, so more training data, including data from different runs can be included.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=[]\n",
    "for file in file_list:\n",
    "    ds   = xr.open_dataset(file)\n",
    "    for time in range(StepSize, len(ds.T.data)-StepSize, SkipOver):\n",
    "        training_data.append([ds.Temp.isel(T=time-StepSize), ds.Temp.isel(T=time), ds.Temp.isel(T=time+StepSize)])\n",
    "        #training_data.append([ds.Temp.isel(T=time-StepSize), ds.Temp.isel(T=time),\n",
    "        #                      ds.S.isel   (T=time-StepSize), ds.S.isel(T=time)   ,\n",
    "        #                      ds.U.isel   (T=time-StepSize), ds.U.isel(T=time)   ,\n",
    "        #                      ds.V.isel   (T=time-StepSize), ds.V.isel(T=time)   ,\n",
    "        #                      ds.Temp.isel(T=time+StepSize),\n",
    "        #    ])\n",
    "    \n",
    "#shuffle dataset\n",
    "random.shuffle(training_data)\n",
    "print(training_data[0][0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put this into X and Y arrays, ready for model to read\n",
    "\n",
    "If using multiple input variables pad with NaN's so the arrays are all the same size (not done above, as it changes them to arrays, and easier to leave as lists) - not needed when just looking at temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "#for feat1,feat2,feat3,feat4,feat5,feat6,feat7,feat8,label in training_data:\n",
    "#        X.append([\n",
    "#            np.pad(feat1.data, ((0,0),(0,1),(0,1)),'constant', constant_values=('NaN')),\n",
    "#            np.pad(feat2.data, ((0,0),(0,1),(0,1)),'constant', constant_values=('NaN')),\n",
    "#            np.pad(feat3.data, ((0,0),(0,1),(0,1)),'constant', constant_values=('NaN')),\n",
    "#            np.pad(feat4.data, ((0,0),(0,1),(0,1)),'constant', constant_values=('NaN')),\n",
    "#            np.pad(feat5.data, ((0,0),(0,1),(0,0)),'constant', constant_values=('NaN')),\n",
    "#            np.pad(feat6.data, ((0,0),(0,1),(0,0)),'constant', constant_values=('NaN')),\n",
    "#            np.pad(feat7.data, ((0,0),(0,0),(0,1)),'constant', constant_values=('NaN')),\n",
    "#            np.pad(feat8.data, ((0,0),(0,0),(0,1)),'constant', constant_values=('NaN')),\n",
    "#             ])\n",
    "#        Y.append(np.pad(label.data, ((0,0),(0,1),(0,1)),'constant', constant_values=('NaN')))\n",
    "\n",
    "for feat1,feat2,label in training_data:\n",
    "        X.append([feat1.data, feat2.data])\n",
    "        Y.append(label.data)\n",
    "\n",
    "# convert to arrays, as model wont accept a list\n",
    "X=np.array(X).transpose(0, 2, 3, 4, 1)\n",
    "Y=np.array(Y)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(X):\n",
    "    X=tf.keras/utils.normalize(X, axis=1)\n",
    "    return X\n",
    "\n",
    "print(X.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN Attempt 1 - an autoencoder type approach\n",
    "\n",
    "I assume that data shape is important here, and so a CNN the way to go, and have tried this with pooling layers, to get something resembling an autoencoder.  Cannot yet get the output shape to match up with the y-fields, due to the odd number of layers, and the pooling vs upscaling does not return the original shape...\n",
    "\n",
    "Also, not convinced auto-encoder approach is best option here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#first downsample/encode\n",
    "model.add(Conv3D(32, (3, 3, 3), input_shape=X.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))  # output shape \n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), padding='same'))             # output shape \n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))  # output shape \n",
    "\n",
    "model.add(Conv3D(128, (3, 3, 3), padding='same'))             # output shape\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Now upsample/decode\n",
    "model.add(Conv3D(128, (3, 3, 3), padding='same'))             # output shape \n",
    "model.add(Activation('relu'))\n",
    "model.add(UpSampling3D(size=(2, 2, 2)))                       # output shape\n",
    "\n",
    "model.add(Conv3D(64, (3, 3, 3), padding='same'))              # output shape \n",
    "model.add(Activation('relu')) \n",
    "model.add(UpSampling3D(size=(2, 2, 2)))                       # output shape \n",
    "\n",
    "model.add(Conv3D(1, (3, 3, 3), padding='same'))              # output shape\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#fit the model - Batch size is how much to pass at once, don't want to pass all at once. \n",
    "#validation split - how much is train vs test data.\n",
    "model.fit(X, Y, batch_size=32, epochs=3, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN attempt 2\n",
    "\n",
    "As Above fails with check, and concerns on whether I should be pooling and thus loosing some information, here I try using just conv layers - no pooling, so no longer autoencoder type set up.\n",
    "\n",
    "This runs, but results are diabolical....\n",
    "\n",
    "Number of inputs = 42*78*11*2 = 72072 inputs. This is huge..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(72072, (3, 3, 3), input_shape=X.shape[1:], padding='same'))  #no shape change with padding...\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv3D(72072, (5, 5, 5), input_shape=X.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv3D(72072, (3, 3, 3), input_shape=X.shape[1:], padding='same'))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, batch_size=128, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN Attemmpt 3:\n",
    "\n",
    "Also tried with Dense layers instead...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#'flatten' inputs\n",
    "model.add(Flatten())   # should be dim 960\n",
    "# define first hidden layer\n",
    "model.add(Dense(72072))\n",
    "model.add(Activation('relu'))\n",
    "#add second hidden layer \n",
    "model.add(Dense(72072))\n",
    "model.add(Activation('relu'))\n",
    "#add third layer - output payer\n",
    "model.add(Dense(72072))\n",
    "#ouput layer should have linear activation function suitable for a regression problem\n",
    "model.add(Activation('linear'))\n",
    "#reshape\n",
    "model.add(Reshape(Y.shape[1:]))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, batch_size=128, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NN Attempt 4\n",
    "\n",
    "A combination of Conv and dense layers..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv3D(72072, (3, 3,3), input_shape=X.shape[1:], padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(72072, (5, 5, 5), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Conv3D(72072, (7, 7, 7), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(72072))\n",
    "#last layer should have linear activation function suitable for a regression problem\n",
    "model.add(Activation('linear'))\n",
    "#reshape\n",
    "model.add(Reshape(Y.shape[1:]))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, batch_size=128, epochs=3, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
